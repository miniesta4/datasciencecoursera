---
title: "PML Project: Qualitative Activity Recognition"
author: "miniesta4"
date: "February 26, 2020"
output: html_document
---

```{r setup, include=FALSE}
# v202002281316

knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(parallel)
library(doParallel)

cl <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cl)

set.seed(20200226)

```

## Introduction

People regularly quantify how much of a particular activity is done, but they 
rarely quantify how well they do it. The goal of this project is to predict
the manner in which six participants do the exercise named "Unilateral Dumbbell 
Biceps Curl" using data from accelerometers on the belt, forearm, arm and dumbbell.

Five different classes have been set. Only the A class is the correct manner:
* Class A: Exactly according to the specification
* Class B: Throwing the elbows to the front
* Class C: Lifting the dumbbell only halfway
* Class D: Lowering the dumbbell only halfway
* Class E: Throwing the hips to the front

The data for this project come from this source: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

## Exploratory data analysis and predictors selection

Dimensions of the data set provided:

```{r ds}
ds <- read.csv("./fics/pml-training.csv", na.strings = c("", "NA", "#DIV/0!"), 
               stringsAsFactors = FALSE)
dim(ds)

```

Partition of the data set into training and testing is done in order to estimate
the test error rate under the validation set approach.

```{r in}
inTrain <- createDataPartition(ds$classe, p = 0.75, list = FALSE)
training <- ds[inTrain, ]
testing <- ds[-inTrain, ]
dim(training)
table(training$classe)
```

First seven columns corresponds to variables which are not related to the way the
exercise is performed. They are removed.

```{r tr}
training[1:5, 1:7]
training <- training[-c(1:7)]
```

Variables with a high proportion of NA's are removed.

```{r pcj}
pcj_nas <- sapply(training, function(x) mean(is.na(x)))
summary(pcj_nas)
table(pcj_nas < 0.1)
hist(pcj_nas)
index_no_nas <- which(pcj_nas < 0.1)
training <- training[index_no_nas]
```

There are not variables with near zero variability.

```{r nzvp, cache=TRUE}
nzvp <- nearZeroVar(training, saveMetrics = TRUE)
nzvp[nzvp$nzv,]
```

Final variables in the training set:
```{r names}
dim(training)
names(training)
table(training$classe)
```

The correlation matrix shows that some variables are highly correlated. This 
situation is known as "Collinearity". It can pose problems in the regression context.

```{r M}
M <- abs(cor(subset(training, select = -classe)))
diag(M) <- 0
hist(M, main = "Training: Correlation among vars selected")
t <- which(M > 0.9, arr.ind=T)
# index_hc <- t[t[, 1] > t[, 2], 1]
```

## Model selection

Collinearity advises against the use of regression models.
Tree-based methods are simple and useful for interpretation.
A tree-based method named CART will be used.

### Classification tree

A classification tree predicts that each observation belongs to the most commonly
occurring class of training observations in the region to which it belongs.

```{r tree, echo=FALSE}
tree.fit <- train(classe ~ ., method = "rpart", data = training)

plot(tree.fit$finalModel)
text(tree.fit$finalModel)
```

Evaluation on the test set.

```{r tree.fit.test, echo=FALSE}
tree.fit.test <- predict(tree.fit, newdata = testing)
confusionMatrix(tree.fit.test, factor(testing$classe))

```

### Boosting

Boosting is an approach for improving prediction results from decision trees.
It is based on growing trees sequentially, using information from previously grown
trees and then combining all of the trees in order to create a single predictive
model.

```{r gbm, echo=FALSE}
# gbm.fit <- train(classe ~ ., method = "gbm", data = training, verbose = FALSE)

```

Evaluation on the test set.

```{r tree.fit.test, echo=FALSE}
gbm.fit.test <- predict(gbm.fit, newdata = testing)
confusionMatrix(gbm.fit.test, factor(testing$classe))

stopCluster(cl)
```


## Conclusion



## Source code

Link to the source code repository:  
https://github.com/miniesta4/datasciencecoursera
